{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.special import expit\n",
    "from generate_data import get_sampler, get_missing_data_sample\n",
    "from missing_data import add_cumulative_estimators, add_cumulative_estimators_pred, mean_estimator_plotter, get_mean_estimators, get_mean_estimators_pred, eval_estimators\n",
    "from numpy.random import default_rng\n",
    "import seaborn as sns\n",
    "#sns.set_theme()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution parameters\n",
    "sigma = 1\n",
    "sample_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798a633ea3954d9db50cc04633a75cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x1ee87e2cf10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 1000\n",
    "r = default_rng(random_seed)\n",
    "sampler = get_sampler(dist=\"SeaVan1\", sigma=sigma)\n",
    "d = sampler(sample_size)\n",
    "sns.jointplot(data=d, x=\"x\", y=\"y\", kind=\"reg\",x_jitter=.1, scatter_kws={\"s\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample from the data generating distribution is plotted above. (The x values in the scatter plot are jittered so it's easier to see the distribution.) Our objective is to estimate the average value of y for this dataset. Unfortunately, we only get a biased sample. When obs is true, we observe x and y, but when obs is false, we only observe x. Below is a plot of the observed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>obs_prob</th>\n",
       "      <th>obs</th>\n",
       "      <th>y</th>\n",
       "      <th>obs_prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.560020</td>\n",
       "      <td>0.482226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>1.314556</td>\n",
       "      <td>0.482226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.239596</td>\n",
       "      <td>0.482226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>False</td>\n",
       "      <td>3.012469</td>\n",
       "      <td>0.023310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.982014</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.376363</td>\n",
       "      <td>0.973222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>False</td>\n",
       "      <td>2.259842</td>\n",
       "      <td>0.023310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0.982014</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.310659</td>\n",
       "      <td>0.973222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0.982014</td>\n",
       "      <td>True</td>\n",
       "      <td>0.426883</td>\n",
       "      <td>0.973222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>False</td>\n",
       "      <td>1.848257</td>\n",
       "      <td>0.023310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538968</td>\n",
       "      <td>0.482226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     x  obs_prob    obs         y  obs_prob_pred\n",
       "0    1  0.500000   True  0.560020       0.482226\n",
       "1    1  0.500000  False  1.314556       0.482226\n",
       "2    1  0.500000   True -0.239596       0.482226\n",
       "3    2  0.017986  False  3.012469       0.023310\n",
       "4    0  0.982014   True -0.376363       0.973222\n",
       "..  ..       ...    ...       ...            ...\n",
       "995  2  0.017986  False  2.259842       0.023310\n",
       "996  0  0.982014   True -1.310659       0.973222\n",
       "997  0  0.982014   True  0.426883       0.973222\n",
       "998  2  0.017986  False  1.848257       0.023310\n",
       "999  1  0.500000   True  0.538968       0.482226\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obs_prob is the propensity generated by using the expit function and obs_prob_pred is the one learned using Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25165c882694581b7d947936135ec0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x1ee89e80f40>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.jointplot(data=d[d[\"obs\"]], x=\"x\", y=\"y\", kind=\"reg\",x_jitter=.1, scatter_kws={\"s\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we take a large sample to get a good estimate of the true population mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of all y's from sample of size 10000000: 1.000250092421415 \n"
     ]
    }
   ],
   "source": [
    "d_big = sampler(n=10000000)\n",
    "seavan1_full_data_mean = np.mean(d_big['y'])\n",
    "print(f\"Mean of all y's from sample of size {d_big.shape[0]}: {seavan1_full_data_mean} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we naively take the mean of the observed y's, we get a heavily biased estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of all _observed_ y's from sample of size 1000: 0.3082255149167164 \n"
     ]
    }
   ],
   "source": [
    "obs_mean = np.mean(d[d[\"obs\"]]['y'])\n",
    "print(f\"Mean of all _observed_ y's from sample of size {d.shape[0]}: {obs_mean} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll generate some other estimators and see how they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d307d447003b4f83b35ccb759e3c58cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ee8afa5940>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#expit propensity\n",
    "sampler = get_sampler(dist=\"SeaVan1\", sigma=sigma, rng = default_rng(1000))\n",
    "d = sampler(sample_size)\n",
    "d = add_cumulative_estimators(d)\n",
    "fig, axs = plt.subplots(2,1, sharex='col')\n",
    "mean_estimator_plotter(d=d, id_col=\"n\", value_cols=[\"ipw_est\"], \n",
    "                       true_mean=seavan1_full_data_mean, include_scatter=False, \n",
    "                       param_dict={\"markers\":False}, ax=axs[0])\n",
    "\n",
    "sns.scatterplot(data=d[d[\"obs\"]], x=\"n\", y=\"y\", hue = \"obs_prob\", size=\"weight\", ax=axs[1], sizes=(3, 100), legend=False) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>obs_prob</th>\n",
       "      <th>obs</th>\n",
       "      <th>y</th>\n",
       "      <th>obs_prob_pred</th>\n",
       "      <th>n</th>\n",
       "      <th>cum_obs_cnt</th>\n",
       "      <th>cum_obs_val</th>\n",
       "      <th>obs_mean</th>\n",
       "      <th>weight</th>\n",
       "      <th>cum_obs_weight</th>\n",
       "      <th>cum_obs_weighted_y</th>\n",
       "      <th>ipw_est</th>\n",
       "      <th>ipw_est_b</th>\n",
       "      <th>ipw_est_b_b</th>\n",
       "      <th>ipw_est_b3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.982014</td>\n",
       "      <td>True</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>0.978823</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>1.018316</td>\n",
       "      <td>1.018316</td>\n",
       "      <td>3.302889</td>\n",
       "      <td>3.302889</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>3.185145</td>\n",
       "      <td>3.127856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.167638</td>\n",
       "      <td>0.514341</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.018316</td>\n",
       "      <td>3.302889</td>\n",
       "      <td>1.651445</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>6.370289</td>\n",
       "      <td>12.511424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>False</td>\n",
       "      <td>1.911987</td>\n",
       "      <td>0.023691</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>55.598150</td>\n",
       "      <td>1.018316</td>\n",
       "      <td>3.302889</td>\n",
       "      <td>1.100963</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>9.555434</td>\n",
       "      <td>28.150704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.097804</td>\n",
       "      <td>0.514341</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.018316</td>\n",
       "      <td>3.302889</td>\n",
       "      <td>0.825722</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>12.740579</td>\n",
       "      <td>50.045696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>False</td>\n",
       "      <td>1.445201</td>\n",
       "      <td>0.023691</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>55.598150</td>\n",
       "      <td>1.018316</td>\n",
       "      <td>3.302889</td>\n",
       "      <td>0.660578</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>15.925723</td>\n",
       "      <td>78.196400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>2.186609</td>\n",
       "      <td>0.514341</td>\n",
       "      <td>996</td>\n",
       "      <td>498</td>\n",
       "      <td>177.941570</td>\n",
       "      <td>0.357312</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1059.011423</td>\n",
       "      <td>1256.216664</td>\n",
       "      <td>1.261262</td>\n",
       "      <td>1.186216</td>\n",
       "      <td>1.115636</td>\n",
       "      <td>1.049256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475430</td>\n",
       "      <td>0.514341</td>\n",
       "      <td>997</td>\n",
       "      <td>498</td>\n",
       "      <td>177.941570</td>\n",
       "      <td>0.357312</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1059.011423</td>\n",
       "      <td>1256.216664</td>\n",
       "      <td>1.259997</td>\n",
       "      <td>1.186216</td>\n",
       "      <td>1.116756</td>\n",
       "      <td>1.051364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0.982014</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.937456</td>\n",
       "      <td>0.978823</td>\n",
       "      <td>998</td>\n",
       "      <td>499</td>\n",
       "      <td>177.004115</td>\n",
       "      <td>0.354718</td>\n",
       "      <td>1.018316</td>\n",
       "      <td>1060.029739</td>\n",
       "      <td>1255.262038</td>\n",
       "      <td>1.257778</td>\n",
       "      <td>1.184176</td>\n",
       "      <td>1.114882</td>\n",
       "      <td>1.049642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.812067</td>\n",
       "      <td>0.514341</td>\n",
       "      <td>999</td>\n",
       "      <td>500</td>\n",
       "      <td>178.816182</td>\n",
       "      <td>0.357632</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1062.029739</td>\n",
       "      <td>1258.886173</td>\n",
       "      <td>1.260146</td>\n",
       "      <td>1.185359</td>\n",
       "      <td>1.115010</td>\n",
       "      <td>1.048836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.139730</td>\n",
       "      <td>0.023691</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>178.816182</td>\n",
       "      <td>0.357632</td>\n",
       "      <td>55.598150</td>\n",
       "      <td>1062.029739</td>\n",
       "      <td>1258.886173</td>\n",
       "      <td>1.258886</td>\n",
       "      <td>1.185359</td>\n",
       "      <td>1.116126</td>\n",
       "      <td>1.050936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     x  obs_prob    obs         y  obs_prob_pred     n  cum_obs_cnt  \\\n",
       "0    0  0.982014   True  3.243483       0.978823     1            1   \n",
       "1    1  0.500000  False  0.167638       0.514341     2            1   \n",
       "2    2  0.017986  False  1.911987       0.023691     3            1   \n",
       "3    1  0.500000  False  0.097804       0.514341     4            1   \n",
       "4    2  0.017986  False  1.445201       0.023691     5            1   \n",
       "..  ..       ...    ...       ...            ...   ...          ...   \n",
       "995  1  0.500000   True  2.186609       0.514341   996          498   \n",
       "996  1  0.500000  False  0.475430       0.514341   997          498   \n",
       "997  0  0.982014   True -0.937456       0.978823   998          499   \n",
       "998  1  0.500000   True  1.812067       0.514341   999          500   \n",
       "999  2  0.017986  False -0.139730       0.023691  1000          500   \n",
       "\n",
       "     cum_obs_val  obs_mean     weight  cum_obs_weight  cum_obs_weighted_y  \\\n",
       "0       3.243483  3.243483   1.018316        1.018316            3.302889   \n",
       "1       3.243483  3.243483   2.000000        1.018316            3.302889   \n",
       "2       3.243483  3.243483  55.598150        1.018316            3.302889   \n",
       "3       3.243483  3.243483   2.000000        1.018316            3.302889   \n",
       "4       3.243483  3.243483  55.598150        1.018316            3.302889   \n",
       "..           ...       ...        ...             ...                 ...   \n",
       "995   177.941570  0.357312   2.000000     1059.011423         1256.216664   \n",
       "996   177.941570  0.357312   2.000000     1059.011423         1256.216664   \n",
       "997   177.004115  0.354718   1.018316     1060.029739         1255.262038   \n",
       "998   178.816182  0.357632   2.000000     1062.029739         1258.886173   \n",
       "999   178.816182  0.357632  55.598150     1062.029739         1258.886173   \n",
       "\n",
       "      ipw_est  ipw_est_b  ipw_est_b_b  ipw_est_b3  \n",
       "0    3.302889   3.243483     3.185145    3.127856  \n",
       "1    1.651445   3.243483     6.370289   12.511424  \n",
       "2    1.100963   3.243483     9.555434   28.150704  \n",
       "3    0.825722   3.243483    12.740579   50.045696  \n",
       "4    0.660578   3.243483    15.925723   78.196400  \n",
       "..        ...        ...          ...         ...  \n",
       "995  1.261262   1.186216     1.115636    1.049256  \n",
       "996  1.259997   1.186216     1.116756    1.051364  \n",
       "997  1.257778   1.184176     1.114882    1.049642  \n",
       "998  1.260146   1.185359     1.115010    1.048836  \n",
       "999  1.258886   1.185359     1.116126    1.050936  \n",
       "\n",
       "[1000 rows x 16 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SeaVan1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2142bf087e0482ba0b951df99d082fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ee8b2d7160>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log_reg propensity\n",
    "sampler = get_sampler(dist=\"SeaVan1\", sigma=sigma, rng = default_rng(1000))\n",
    "d1 = sampler(sample_size)\n",
    "d1 = add_cumulative_estimators_pred(d1)\n",
    "fig, axs = plt.subplots(2,1, sharex='col')\n",
    "mean_estimator_plotter(d=d1, id_col=\"n\", value_cols=[\"ipw_est_pred\"], \n",
    "                       true_mean=seavan1_full_data_mean, include_scatter=False, \n",
    "                       param_dict={\"markers\":False}, ax=axs[0])\n",
    "\n",
    "sns.scatterplot(data=d1[d1[\"obs\"]], x=\"n\", y=\"y\", hue = \"obs_prob_pred\", size=\"weight_pred\", ax=axs[1], sizes=(3, 100), legend=False) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>obs_prob</th>\n",
       "      <th>obs</th>\n",
       "      <th>y</th>\n",
       "      <th>obs_prob_pred</th>\n",
       "      <th>n</th>\n",
       "      <th>cum_obs_cnt</th>\n",
       "      <th>cum_obs_val</th>\n",
       "      <th>obs_mean</th>\n",
       "      <th>weight_pred</th>\n",
       "      <th>cum_obs_weight_pred</th>\n",
       "      <th>cum_obs_weighted_y_pred</th>\n",
       "      <th>ipw_est_pred</th>\n",
       "      <th>ipw_est_b_pred</th>\n",
       "      <th>ipw_est_b_b_pred</th>\n",
       "      <th>ipw_est_b3_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.982014</td>\n",
       "      <td>True</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>0.978823</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>1.021635</td>\n",
       "      <td>1.021635</td>\n",
       "      <td>3.313655</td>\n",
       "      <td>3.313655</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>3.174797</td>\n",
       "      <td>3.107565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.167638</td>\n",
       "      <td>0.514341</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>1.944235</td>\n",
       "      <td>1.021635</td>\n",
       "      <td>3.313655</td>\n",
       "      <td>1.656827</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>6.349593</td>\n",
       "      <td>12.430261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>False</td>\n",
       "      <td>1.911987</td>\n",
       "      <td>0.023691</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>42.210552</td>\n",
       "      <td>1.021635</td>\n",
       "      <td>3.313655</td>\n",
       "      <td>1.104552</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>9.524390</td>\n",
       "      <td>27.968087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.097804</td>\n",
       "      <td>0.514341</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>1.944235</td>\n",
       "      <td>1.021635</td>\n",
       "      <td>3.313655</td>\n",
       "      <td>0.828414</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>12.699187</td>\n",
       "      <td>49.721044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>False</td>\n",
       "      <td>1.445201</td>\n",
       "      <td>0.023691</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>42.210552</td>\n",
       "      <td>1.021635</td>\n",
       "      <td>3.313655</td>\n",
       "      <td>0.662731</td>\n",
       "      <td>3.243483</td>\n",
       "      <td>15.873983</td>\n",
       "      <td>77.689132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>2.186609</td>\n",
       "      <td>0.514341</td>\n",
       "      <td>996</td>\n",
       "      <td>498</td>\n",
       "      <td>177.941570</td>\n",
       "      <td>0.357312</td>\n",
       "      <td>1.944235</td>\n",
       "      <td>956.706424</td>\n",
       "      <td>1023.398684</td>\n",
       "      <td>1.027509</td>\n",
       "      <td>1.069710</td>\n",
       "      <td>1.113645</td>\n",
       "      <td>1.159384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475430</td>\n",
       "      <td>0.514341</td>\n",
       "      <td>997</td>\n",
       "      <td>498</td>\n",
       "      <td>177.941570</td>\n",
       "      <td>0.357312</td>\n",
       "      <td>1.944235</td>\n",
       "      <td>956.706424</td>\n",
       "      <td>1023.398684</td>\n",
       "      <td>1.026478</td>\n",
       "      <td>1.069710</td>\n",
       "      <td>1.114763</td>\n",
       "      <td>1.161714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0.982014</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.937456</td>\n",
       "      <td>0.978823</td>\n",
       "      <td>998</td>\n",
       "      <td>499</td>\n",
       "      <td>177.004115</td>\n",
       "      <td>0.354718</td>\n",
       "      <td>1.021635</td>\n",
       "      <td>957.728059</td>\n",
       "      <td>1022.440947</td>\n",
       "      <td>1.024490</td>\n",
       "      <td>1.067569</td>\n",
       "      <td>1.112460</td>\n",
       "      <td>1.159238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.812067</td>\n",
       "      <td>0.514341</td>\n",
       "      <td>999</td>\n",
       "      <td>500</td>\n",
       "      <td>178.816182</td>\n",
       "      <td>0.357632</td>\n",
       "      <td>1.944235</td>\n",
       "      <td>959.672294</td>\n",
       "      <td>1025.964032</td>\n",
       "      <td>1.026991</td>\n",
       "      <td>1.069077</td>\n",
       "      <td>1.112889</td>\n",
       "      <td>1.158495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.139730</td>\n",
       "      <td>0.023691</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>178.816182</td>\n",
       "      <td>0.357632</td>\n",
       "      <td>42.210552</td>\n",
       "      <td>959.672294</td>\n",
       "      <td>1025.964032</td>\n",
       "      <td>1.025964</td>\n",
       "      <td>1.069077</td>\n",
       "      <td>1.114003</td>\n",
       "      <td>1.160816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     x  obs_prob    obs         y  obs_prob_pred     n  cum_obs_cnt  \\\n",
       "0    0  0.982014   True  3.243483       0.978823     1            1   \n",
       "1    1  0.500000  False  0.167638       0.514341     2            1   \n",
       "2    2  0.017986  False  1.911987       0.023691     3            1   \n",
       "3    1  0.500000  False  0.097804       0.514341     4            1   \n",
       "4    2  0.017986  False  1.445201       0.023691     5            1   \n",
       "..  ..       ...    ...       ...            ...   ...          ...   \n",
       "995  1  0.500000   True  2.186609       0.514341   996          498   \n",
       "996  1  0.500000  False  0.475430       0.514341   997          498   \n",
       "997  0  0.982014   True -0.937456       0.978823   998          499   \n",
       "998  1  0.500000   True  1.812067       0.514341   999          500   \n",
       "999  2  0.017986  False -0.139730       0.023691  1000          500   \n",
       "\n",
       "     cum_obs_val  obs_mean  weight_pred  cum_obs_weight_pred  \\\n",
       "0       3.243483  3.243483     1.021635             1.021635   \n",
       "1       3.243483  3.243483     1.944235             1.021635   \n",
       "2       3.243483  3.243483    42.210552             1.021635   \n",
       "3       3.243483  3.243483     1.944235             1.021635   \n",
       "4       3.243483  3.243483    42.210552             1.021635   \n",
       "..           ...       ...          ...                  ...   \n",
       "995   177.941570  0.357312     1.944235           956.706424   \n",
       "996   177.941570  0.357312     1.944235           956.706424   \n",
       "997   177.004115  0.354718     1.021635           957.728059   \n",
       "998   178.816182  0.357632     1.944235           959.672294   \n",
       "999   178.816182  0.357632    42.210552           959.672294   \n",
       "\n",
       "     cum_obs_weighted_y_pred  ipw_est_pred  ipw_est_b_pred  ipw_est_b_b_pred  \\\n",
       "0                   3.313655      3.313655        3.243483          3.174797   \n",
       "1                   3.313655      1.656827        3.243483          6.349593   \n",
       "2                   3.313655      1.104552        3.243483          9.524390   \n",
       "3                   3.313655      0.828414        3.243483         12.699187   \n",
       "4                   3.313655      0.662731        3.243483         15.873983   \n",
       "..                       ...           ...             ...               ...   \n",
       "995              1023.398684      1.027509        1.069710          1.113645   \n",
       "996              1023.398684      1.026478        1.069710          1.114763   \n",
       "997              1022.440947      1.024490        1.067569          1.112460   \n",
       "998              1025.964032      1.026991        1.069077          1.112889   \n",
       "999              1025.964032      1.025964        1.069077          1.114003   \n",
       "\n",
       "     ipw_est_b3_pred  \n",
       "0           3.107565  \n",
       "1          12.430261  \n",
       "2          27.968087  \n",
       "3          49.721044  \n",
       "4          77.689132  \n",
       "..               ...  \n",
       "995         1.159384  \n",
       "996         1.161714  \n",
       "997         1.159238  \n",
       "998         1.158495  \n",
       "999         1.160816  \n",
       "\n",
       "[1000 rows x 16 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63561a8fbff64e39953ff4de8aa9aa4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ee8b37e100>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#expit propensity\n",
    "fig, axs = plt.subplots(2,1, sharex='col')\n",
    "mean_estimator_plotter(d=d, id_col=\"n\", value_cols=[\"ipw_est\", \"ipw_est_b\"], \n",
    "                       true_mean=seavan1_full_data_mean, include_scatter=False, \n",
    "                       param_dict={\"markers\":False}, ax=axs[0])\n",
    "\n",
    "sns.scatterplot(data=d[d[\"obs\"]], x=\"n\", y=\"y\", hue = \"obs_prob\", size=\"weight\", \n",
    "                ax=axs[1], sizes=(3, 100), legend=False) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb4f83e6ef74e4da7ac48b574d23c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ee8c665760>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log_reg propensity\n",
    "fig, axs = plt.subplots(2,1, sharex='col')\n",
    "mean_estimator_plotter(d=d1, id_col=\"n\", value_cols=[\"ipw_est_pred\", \"ipw_est_b_pred\"], \n",
    "                       true_mean=seavan1_full_data_mean, include_scatter=False, \n",
    "                       param_dict={\"markers\":False}, ax=axs[0])\n",
    "\n",
    "sns.scatterplot(data=d1[d1[\"obs\"]], x=\"n\", y=\"y\", hue = \"obs_prob_pred\", size=\"weight_pred\", \n",
    "                ax=axs[1], sizes=(3, 100), legend=False) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expit propensity\n",
    "sampler = get_sampler(dist=\"SeaVan1\", sigma=sigma, rng = default_rng(5))\n",
    "num_repeats = 5000  #use 5000 for better SEs\n",
    "data_list = []\n",
    "num_obs_list = []\n",
    "for i in range(num_repeats):\n",
    "    ## Randomly choose observations\n",
    "    d = sampler(n=sample_size)\n",
    "    est = get_mean_estimators(vals=d['y'],\n",
    "                              covar=d[[\"x\"]],\n",
    "                              propensities=d[\"obs_prob\"],\n",
    "                              obs=d['obs'])\n",
    "    data_list.append(est)\n",
    "    num_obs_list.append(d['obs'].sum())\n",
    "results_seavan1 = pd.DataFrame(data_list)\n",
    "#results = results_seavan1\n",
    "#estimators_to_keep = [\"ipw_mean\", \"ipw_b_mean\", \"ipw_b_b_mean\"]\n",
    "#a = results[estimators_to_keep].apply(eval_estimators, axis=0, raw=True, \n",
    "#                                      result_type=\"expand\", true_val=seavan1_full_data_mean)\n",
    "#results_eval = pd.DataFrame(a.to_dict())\n",
    "#print(results_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_reg propensity\n",
    "sampler = get_sampler(dist=\"SeaVan1\", sigma=sigma, rng = default_rng(5))\n",
    "num_repeats = 5000  #use 5000 for better SEs\n",
    "data_list = []\n",
    "num_obs_list = []\n",
    "for i in range(num_repeats):\n",
    "    ## Randomly choose observations\n",
    "    d = sampler(n=sample_size)\n",
    "    est = get_mean_estimators_pred(vals=d['y'],\n",
    "                              covar=d[[\"x\"]],\n",
    "                              propensities=d[\"obs_prob_pred\"],\n",
    "                              obs=d['obs'])\n",
    "    data_list.append(est)\n",
    "    num_obs_list.append(d['obs'].sum())\n",
    "results_seavan1_pred = pd.DataFrame(data_list)\n",
    "#results = results_seavan1_pred\n",
    "#estimators_to_keep = [\"ipw_mean_pred\", \"ipw_b_mean_pred\", \"ipw_b_b_mean_pred\"]\n",
    "#a = results[estimators_to_keep].apply(eval_estimators, axis=0, raw=True, \n",
    "#                                      result_type=\"expand\", true_val=seavan1_full_data_mean)\n",
    "#results_eval = pd.DataFrame(a.to_dict())\n",
    "#print(results_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ipw_mean  ipw_mean_pred  ipw_b_mean  ipw_b_mean_pred  \\\n",
      "mean          0.995142       0.828959    0.978119         0.897344   \n",
      "SD            0.308634       0.179947    0.197319         0.151429   \n",
      "SE            0.004365       0.002545    0.002791         0.002142   \n",
      "bias         -0.005108      -0.171291   -0.022131        -0.102906   \n",
      "mean_abs_err  0.244294       0.205381    0.158224         0.146352   \n",
      "RMS error     0.308677       0.248438    0.198556         0.183086   \n",
      "\n",
      "              ipw_b_b_mean  ipw_b_b_mean_pred  \n",
      "mean              0.978854           0.976601  \n",
      "SD                0.145780           0.137767  \n",
      "SE                0.002062           0.001948  \n",
      "bias             -0.021396          -0.023650  \n",
      "mean_abs_err      0.116468           0.109722  \n",
      "RMS error         0.147342           0.139782  \n"
     ]
    }
   ],
   "source": [
    "results = pd.concat([results_seavan1, results_seavan1_pred], axis=1)\n",
    "\n",
    "estimators_to_keep = [\"ipw_mean\", \"ipw_mean_pred\", \"ipw_b_mean\", \"ipw_b_mean_pred\", \"ipw_b_b_mean\", \"ipw_b_b_mean_pred\"]\n",
    "a = results[estimators_to_keep].apply(eval_estimators, axis=0, raw=True, \n",
    "                                      result_type=\"expand\", true_val=seavan1_full_data_mean)\n",
    "results_eval = pd.DataFrame(a.to_dict())\n",
    "print(results_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison\n",
    "\n",
    "The bias is relatively small for the trained estimators. The respective learned estimators have lower SE compared to their trained counterparts and its lower for the self-normalised and even lower for the twice self-normalised estimators. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The twice self-normalized estimator has improved performance, presumably by removing the rest of the variation caused by correlation between the total weight and the estimate. More precisely, conditional on the total weight, the ipw and even the ipw_b estimators have a significant bias that is positively correlated with the weight. When we combine all these estimates together, the positive and negative biases inflate the overall variance of the estimator. I think the takeaway here is that there is no estimator that is \"best\" for all distributions. The ipw_b_b estimator happens to work quite well for this distribution, because even self-normalizing didn't review all of the correlation with the weight. But this isn't the case for other distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now consider a different kind of estimator: imputation estimators. The approach we consider here is to build a model for the expectation of Y given X, using the complete cases. Then impute the predictions for the incomplete cases. We then take the average of the Y's and imputed Y's, as though it were the full data set. For illustration, below we consider a linear fit of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ipw_mean  ipw_mean_pred  ipw_b_mean  ipw_b_mean_pred  \\\n",
      "mean          0.995142       0.828959    0.978119         0.897344   \n",
      "SD            0.308634       0.179947    0.197319         0.151429   \n",
      "SE            0.004365       0.002545    0.002791         0.002142   \n",
      "bias         -0.005108      -0.171291   -0.022131        -0.102906   \n",
      "mean_abs_err  0.244294       0.205381    0.158224         0.146352   \n",
      "RMS error     0.308677       0.248438    0.198556         0.183086   \n",
      "\n",
      "              impute_missing  impute_missing_pred  impute_missing_w  \\\n",
      "mean                0.998938             0.998938          0.997538   \n",
      "SD                  0.077668             0.077668          0.148349   \n",
      "SE                  0.001098             0.001098          0.002098   \n",
      "bias               -0.001312            -0.001312         -0.002712   \n",
      "mean_abs_err        0.061657             0.061657          0.116538   \n",
      "RMS error           0.077679             0.077679          0.148374   \n",
      "\n",
      "              impute_missing_w_pred  \n",
      "mean                       0.997530  \n",
      "SD                         0.144599  \n",
      "SE                         0.002045  \n",
      "bias                      -0.002720  \n",
      "mean_abs_err               0.113075  \n",
      "RMS error                  0.144624  \n"
     ]
    }
   ],
   "source": [
    "estimators_to_keep = [\"ipw_mean\", \"ipw_mean_pred\", \"ipw_b_mean\", \"ipw_b_mean_pred\", \"impute_missing\", \"impute_missing_pred\", \n",
    "                      \"impute_missing_w\", \"impute_missing_w_pred\"]\n",
    "a = results[estimators_to_keep].apply(eval_estimators, axis=0, raw=True, \n",
    "                                      result_type=\"expand\", true_val=seavan1_full_data_mean)\n",
    "results_eval = pd.DataFrame(a.to_dict())\n",
    "print(results_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison \n",
    "\n",
    "impute_missing and impute_missing_pred have the same performance since both use the same set of variables. However, impute_missing_w_pred is performing slightly better than impute_missing_w (lower SE and errors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With impute_missing, we build a regression estimator for the missing values. The regression estimator has only 2 degrees of freedom and roughly sample_size/2 observations. This will lead to very low variance estimate of the regression model. However, more is reflected in SD than just that variance. In general, even with infinite data, the regression prediction may be wrong for certain x's because of model bias -- i.e. the true conditional distribution is not represented well in our class of models. These errors, while a consistent \"bias\" for individual x's, just look like noise when averaged across the x's. Thus this kind of error may also show up in the SD. If the errors for each x do not cancel out, on average, then we will end up with a bias. We will see this happening when we have data missing at random, with a model mismatch, and we don't propensity weight the training examples for the regession."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the impute_missing_w estimator, we're using inverse propensity weighting in fitting the linear regression. We would expect this to potentially decrease the bias of the estimator at the expense of an increase in variance. However, this model has no bias because it perfectly matches the distribution. The bias doesn't seem much bigger than 0 (in terms of SE's), though the SD and RMSE is twice as large than the imputation estimator without IPW.\n",
    "\n",
    "For this particular distribution, imputing with a linear model works tremendously well. Both the SD and the bias, as well as our two error measures, are the lowest on the board. However, this is largely due to the fact that a linear model is a perfect fit for the data distribution. We'll now repeat this experiment with the modified dataset, in which the conditional mean of y is not a linear function of x. Now Y has mean 1 whether x=1.0 or 2.0, but has mean 0 for x=0.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SeaVan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a221a95cc8b45c8af820313afd40207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\axisgrid.py:1668: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  f = plt.figure(figsize=(height, height))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e83660e9a047a1b049f54bbe0a4ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of all y's from sample of size 10000000: 0.6660777856749452 \n"
     ]
    }
   ],
   "source": [
    "sigma = 1\n",
    "random_seed = 1000\n",
    "sample_size = 1000\n",
    "r = default_rng(random_seed)\n",
    "sampler = get_sampler(dist=\"SeaVan2\", sigma=sigma)\n",
    "d = sampler(sample_size)\n",
    "sns.jointplot(data=d, x=\"x\", y=\"y\", kind=\"reg\",x_jitter=.1, scatter_kws={\"s\": 1})\n",
    "sns.jointplot(data=d[d[\"obs\"]], x=\"x\", y=\"y\", kind=\"reg\",x_jitter=.1, scatter_kws={\"s\": 1})\n",
    "d_big = sampler(n=10000000)\n",
    "seavan2_full_data_mean = np.mean(d_big['y'])\n",
    "print(f\"Mean of all y's from sample of size {d_big.shape[0]}: {seavan2_full_data_mean} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plot above is of the full dataset, while the second is from the observed portion of the dataset. An unweighted linear fit is given through each set of points. Note that the fit changes substantially when we leave out the missing data, as opposed to the first data distribution we examined. The hope is that by inverse propensity weighting the observed points in the linear fit, we can get a better approximation to the linear fit of the fully observed data.\n",
    "\n",
    "In the first scatter plot, we see that the best a linear fit can do with this nonlinear relation. The mismatch of the model to the data gives rise to a bias that we will call model bias. In the second scatter plot, which shows the data we actually observe, we see that the linear fit significantly overestimates the mean of y for x=2. Here the model bias is exacerbated by a sample bias. Here are the results for our various estimators on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expit propensity\n",
    "num_repeats = 1000  #use 5000 for better SEs\n",
    "random_seed = 1000\n",
    "rng = default_rng(random_seed)\n",
    "sampler = get_sampler(dist=\"SeaVan2\", sigma=sigma, rng = rng)\n",
    "data_list = []\n",
    "num_obs_list = []\n",
    "for i in range(num_repeats):\n",
    "    ## Randomly choose observations\n",
    "    d = sampler(n=sample_size)\n",
    "    est = get_mean_estimators(vals=d['y'],\n",
    "                              covar=d[[\"x\"]],\n",
    "                              propensities=d[\"obs_prob\"],\n",
    "                              obs=d['obs'])\n",
    "    data_list.append(est)\n",
    "    num_obs_list.append(d['obs'].sum())\n",
    "results_seavan2 = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_reg propensity\n",
    "num_repeats = 1000  #use 5000 for better SEs\n",
    "random_seed = 1000\n",
    "rng = default_rng(random_seed)\n",
    "sampler = get_sampler(dist=\"SeaVan2\", sigma=sigma, rng = rng)\n",
    "data_list = []\n",
    "num_obs_list = []\n",
    "for i in range(num_repeats):\n",
    "    ## Randomly choose observations\n",
    "    d = sampler(n=sample_size)\n",
    "    est = get_mean_estimators_pred(vals=d['y'],\n",
    "                              covar=d[[\"x\"]],\n",
    "                              propensities=d[\"obs_prob_pred\"],\n",
    "                              obs=d['obs'])\n",
    "    data_list.append(est)\n",
    "    num_obs_list.append(d['obs'].sum())\n",
    "results_seavan2_pred = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of all y's from sample of size 10000000: 0.6667028542738604 \n"
     ]
    }
   ],
   "source": [
    "d_big = sampler(n=10000000)\n",
    "seavan2_full_data_mean = np.mean(d_big['y'])\n",
    "print(f\"Mean of all y's from sample of size {d_big.shape[0]}: {seavan2_full_data_mean} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ipw_mean  ipw_mean_pred  ipw_b_mean  ipw_b_mean_pred  \\\n",
      "mean          0.673968       0.586963    0.665035         0.636445   \n",
      "SD            0.189785       0.125457    0.141190         0.119475   \n",
      "SE            0.006002       0.003967    0.004465         0.003778   \n",
      "bias          0.007265      -0.079739   -0.001668        -0.030258   \n",
      "mean_abs_err  0.152396       0.121636    0.112997         0.097530   \n",
      "RMS error     0.189924       0.148654    0.141200         0.123247   \n",
      "\n",
      "              impute_missing  impute_missing_pred  impute_missing_w  \\\n",
      "mean                0.940288             0.940288          0.678548   \n",
      "SD                  0.079358             0.079358          0.146519   \n",
      "SE                  0.002510             0.002510          0.004633   \n",
      "bias                0.273585             0.273585          0.011845   \n",
      "mean_abs_err        0.273585             0.273585          0.114784   \n",
      "RMS error           0.284863             0.284863          0.146997   \n",
      "\n",
      "              impute_missing_w_pred  ipw_dr_1  ipw_dr_1_pred  ipw_dr_w_1  \\\n",
      "mean                       0.692951  0.669578       0.743039    0.678548   \n",
      "SD                         0.141605  0.181370       0.132958    0.146519   \n",
      "SE                         0.004478  0.005735       0.004205    0.004633   \n",
      "bias                       0.026248  0.002876       0.076336    0.011845   \n",
      "mean_abs_err               0.112065  0.143238       0.122743    0.114784   \n",
      "RMS error                  0.144017  0.181393       0.153314    0.146997   \n",
      "\n",
      "              ipw_dr_w_1_pred  ipw_dr_opt  ipw_dr_opt_pred  ipw_dr_w_opt  \\\n",
      "mean                 0.692893    0.669578         0.743039      0.678548   \n",
      "SD                   0.141576    0.181370         0.132958      0.146519   \n",
      "SE                   0.004477    0.005735         0.004205      0.004633   \n",
      "bias                 0.026190    0.002876         0.076336      0.011845   \n",
      "mean_abs_err         0.112058    0.143238         0.122743      0.114784   \n",
      "RMS error            0.143978    0.181393         0.153314      0.146997   \n",
      "\n",
      "              ipw_dr_w_opt_pred  ipw_dr_b  ipw_dr_b_pred  ipw_dr_w_b  \\\n",
      "mean                   0.692893  0.657434       0.679070    0.677829   \n",
      "SD                     0.141576  0.149469       0.107079    0.151611   \n",
      "SE                     0.004477  0.004727       0.003386    0.004794   \n",
      "bias                   0.026190 -0.009269       0.012368    0.011127   \n",
      "mean_abs_err           0.112058  0.114273       0.084556    0.121809   \n",
      "RMS error              0.143978  0.149756       0.107791    0.152019   \n",
      "\n",
      "              ipw_dr_w_b_pred  \n",
      "mean                 0.635356  \n",
      "SD                   0.126642  \n",
      "SE                   0.004005  \n",
      "bias                -0.031347  \n",
      "mean_abs_err         0.102446  \n",
      "RMS error            0.130464  \n"
     ]
    }
   ],
   "source": [
    "results = pd.concat([results_seavan2, results_seavan2_pred], axis=1)\n",
    "\n",
    "estimators_to_keep = [\"ipw_mean\", \"ipw_mean_pred\", \"ipw_b_mean\", \"ipw_b_mean_pred\", \"impute_missing\", \"impute_missing_pred\", \n",
    "                     \"impute_missing_w\", \"impute_missing_w_pred\", \"ipw_dr_1\", \"ipw_dr_1_pred\", \"ipw_dr_w_1\", \"ipw_dr_w_1_pred\", \n",
    "                      \"ipw_dr_opt\", \"ipw_dr_opt_pred\", \"ipw_dr_w_opt\", \"ipw_dr_w_opt_pred\",\n",
    "                      \"ipw_dr_b\", \"ipw_dr_b_pred\", \"ipw_dr_w_b\", \"ipw_dr_w_b_pred\"]\n",
    "a = results[estimators_to_keep].apply(eval_estimators, axis=0, raw=True, \n",
    "                                      result_type=\"expand\", true_val=seavan2_full_data_mean)\n",
    "results_eval = pd.DataFrame(a.to_dict())\n",
    "print(results_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison\n",
    "\n",
    "The bias is low and SD is high for ipw_mean and ipw_b_mean, the SD of the respective learned estimators have improved but at the cost of increasing the bias. The opposite is the case for the impute_missing estimators. For all the ipw_dr estimators, the learned estimators lower the SD at the price of increasng the bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SeaVanMod2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expit propensity\n",
    "num_repeats = 1000  #use 5000 for better SEs\n",
    "random_seed = 1000\n",
    "rng = default_rng(random_seed)\n",
    "sampler = get_sampler(dist=\"SeaVanMod2\", sigma=sigma, rng = rng)\n",
    "data_list = []\n",
    "num_obs_list = []\n",
    "for i in range(num_repeats):\n",
    "    ## Randomly choose observations\n",
    "    d = sampler(n=sample_size)\n",
    "    est = get_mean_estimators(vals=d['y'],\n",
    "                              covar=d[[\"x\"]],\n",
    "                              propensities=d[\"obs_prob\"],\n",
    "                              obs=d['obs'])\n",
    "    data_list.append(est)\n",
    "    num_obs_list.append(d['obs'].sum())\n",
    "results_seavanMod2 = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_reg propensity\n",
    "num_repeats = 1000  #use 5000 for better SEs\n",
    "random_seed = 1000\n",
    "rng = default_rng(random_seed)\n",
    "sampler = get_sampler(dist=\"SeaVanMod2\", sigma=sigma, rng = rng)\n",
    "data_list = []\n",
    "num_obs_list = []\n",
    "for i in range(num_repeats):\n",
    "    ## Randomly choose observations\n",
    "    d = sampler(n=sample_size)\n",
    "    est = get_mean_estimators_pred(vals=d['y'],\n",
    "                              covar=d[[\"x\"]],\n",
    "                              propensities=d[\"obs_prob_pred\"],\n",
    "                              obs=d['obs'])\n",
    "    data_list.append(est)\n",
    "    num_obs_list.append(d['obs'].sum())\n",
    "results_seavanMod2_pred = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of all y's from sample of size 10000000: 1.6676854683793805 \n"
     ]
    }
   ],
   "source": [
    "d_big = sampler(n=10000000)\n",
    "seavanmod2_full_data_mean = np.mean(d_big['y'])\n",
    "print(f\"Mean of all y's from sample of size {d_big.shape[0]}: {seavanmod2_full_data_mean} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ipw_mean  ipw_mean_pred  ipw_b_mean  ipw_b_mean_pred  \\\n",
      "mean          1.690247       1.340515    1.641711         1.443464   \n",
      "SD            0.545853       0.295947    0.340242         0.235740   \n",
      "SE            0.017261       0.009359    0.010759         0.007455   \n",
      "bias          0.022561      -0.327170   -0.025975        -0.224222   \n",
      "mean_abs_err  0.435857       0.366312    0.272981         0.262279   \n",
      "RMS error     0.546319       0.441163    0.341232         0.325344   \n",
      "\n",
      "              impute_missing  impute_missing_pred  impute_missing_w  \\\n",
      "mean                1.125976             1.125976          1.654647   \n",
      "SD                  0.092203             0.092203          0.163546   \n",
      "SE                  0.002916             0.002916          0.005172   \n",
      "bias               -0.541709            -0.541709         -0.013038   \n",
      "mean_abs_err        0.541709             0.541709          0.129804   \n",
      "RMS error           0.549500             0.549500          0.164065   \n",
      "\n",
      "              impute_missing_w_pred  \n",
      "mean                       1.626516  \n",
      "SD                         0.157587  \n",
      "SE                         0.004983  \n",
      "bias                      -0.041169  \n",
      "mean_abs_err               0.127758  \n",
      "RMS error                  0.162876  \n"
     ]
    }
   ],
   "source": [
    "results = pd.concat([results_seavanMod2, results_seavanMod2_pred], axis=1)\n",
    "\n",
    "estimators_to_keep = [\"ipw_mean\", \"ipw_mean_pred\", \"ipw_b_mean\", \"ipw_b_mean_pred\", \"impute_missing\", \"impute_missing_pred\", \n",
    "                     \"impute_missing_w\", \"impute_missing_w_pred\"]\n",
    "a = results[estimators_to_keep].apply(eval_estimators, axis=0, raw=True, \n",
    "                                      result_type=\"expand\", true_val=seavanmod2_full_data_mean)\n",
    "results_eval = pd.DataFrame(a.to_dict())\n",
    "print(results_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\axisgrid.py:1668: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  f = plt.figure(figsize=(height, height))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2ad1521c584c86bcf05c2e3de3b436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\axisgrid.py:1668: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  f = plt.figure(figsize=(height, height))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a66e4f79ad4efd8152fdf1d459e4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x1ee8cc2b3d0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.jointplot(data=d, x=\"x\", y=\"y\", kind=\"reg\",x_jitter=.1, scatter_kws={\"s\": 1})\n",
    "sns.jointplot(data=d[d[\"obs\"]], x=\"x\", y=\"y\", kind=\"reg\",x_jitter=.1, scatter_kws={\"s\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCAR_normal_sqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of all y's from sample of size 10000000: 3.002234668379598 \n"
     ]
    }
   ],
   "source": [
    "#expit propensity\n",
    "num_repeats = 1000  #use 5000 for better SEs\n",
    "random_seed = 1000\n",
    "sigma = 1\n",
    "obs_prob = 0.1\n",
    "rng = default_rng(random_seed)\n",
    "sampler = get_sampler(dist=\"MCAR_normal_sqr\", sigma=sigma, obs_prob=obs_prob, rng = rng)\n",
    "data_list = []\n",
    "num_obs_list = []\n",
    "for i in range(num_repeats):\n",
    "    ## Randomly choose observations\n",
    "    d = sampler(n=sample_size)\n",
    "    est = get_mean_estimators(vals=d['y'],\n",
    "                              covar=d[[\"x\"]],\n",
    "                              propensities=d[\"obs_prob\"],\n",
    "                              obs=d['obs'])\n",
    "    data_list.append(est)\n",
    "    num_obs_list.append(d['obs'].sum())\n",
    "results_MCAR_normal_sqr = pd.DataFrame(data_list)\n",
    "d_big = sampler(n=10000000)\n",
    "MCAR_normal_sqr_full_data_mean = np.mean(d_big['y'])\n",
    "print(f\"Mean of all y's from sample of size {d_big.shape[0]}: {MCAR_normal_sqr_full_data_mean} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of all y's from sample of size 10000000: 3.002234668379598 \n"
     ]
    }
   ],
   "source": [
    "#log_reg propensity\n",
    "num_repeats = 1000  #use 5000 for better SEs\n",
    "random_seed = 1000\n",
    "sigma = 1\n",
    "obs_prob = 0.1\n",
    "rng = default_rng(random_seed)\n",
    "sampler = get_sampler(dist=\"MCAR_normal_sqr\", sigma=sigma, obs_prob=obs_prob, rng = rng)\n",
    "data_list = []\n",
    "num_obs_list = []\n",
    "for i in range(num_repeats):\n",
    "    ## Randomly choose observations\n",
    "    d = sampler(n=sample_size)\n",
    "    est = get_mean_estimators_pred(vals=d['y'],\n",
    "                              covar=d[[\"x\"]],\n",
    "                              propensities=d[\"obs_prob_pred\"],\n",
    "                              obs=d['obs'])\n",
    "    data_list.append(est)\n",
    "    num_obs_list.append(d['obs'].sum())\n",
    "results_MCAR_normal_sqr_pred = pd.DataFrame(data_list)\n",
    "d_big = sampler(n=10000000)\n",
    "MCAR_normal_sqr_full_data_mean_pred = np.mean(d_big['y'])\n",
    "print(f\"Mean of all y's from sample of size {d_big.shape[0]}: {MCAR_normal_sqr_full_data_mean_pred} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ipw_mean  ipw_mean_pred  ipw_b_mean  ipw_b_mean_pred  \\\n",
      "mean          2.975643       2.997494    2.982905         2.997883   \n",
      "SD            0.468419       0.197088    0.364441         0.196488   \n",
      "SE            0.014813       0.006232    0.011525         0.006213   \n",
      "bias         -0.026591      -0.004741   -0.019330        -0.004352   \n",
      "mean_abs_err  0.375287       0.157111    0.289040         0.156575   \n",
      "RMS error     0.469173       0.197145    0.364953         0.196536   \n",
      "\n",
      "              impute_missing  impute_missing_pred  \n",
      "mean                2.993700             2.993700  \n",
      "SD                  0.196990             0.196990  \n",
      "SE                  0.006229             0.006229  \n",
      "bias               -0.008535            -0.008535  \n",
      "mean_abs_err        0.157176             0.157176  \n",
      "RMS error           0.197175             0.197175  \n"
     ]
    }
   ],
   "source": [
    "results = pd.concat([results_MCAR_normal_sqr, results_MCAR_normal_sqr_pred], axis=1)\n",
    "\n",
    "estimators_to_keep = [\"ipw_mean\", \"ipw_mean_pred\", \"ipw_b_mean\", \"ipw_b_mean_pred\", \"impute_missing\", \"impute_missing_pred\"]\n",
    "a = results[estimators_to_keep].apply(eval_estimators, axis=0, raw=True, \n",
    "                                      result_type=\"expand\", true_val=MCAR_normal_sqr_full_data_mean)\n",
    "results_eval = pd.DataFrame(a.to_dict())\n",
    "print(results_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison\n",
    "\n",
    "The learned estimators are much better than the trained ones in terms of both bias and SD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\axisgrid.py:1668: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  f = plt.figure(figsize=(height, height))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a782748a14429da1cd2a83c9b74421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x1ee87a74190>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.jointplot(data=d, x=\"x\", y=\"y\", kind=\"reg\",x_jitter=.1, scatter_kws={\"s\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
